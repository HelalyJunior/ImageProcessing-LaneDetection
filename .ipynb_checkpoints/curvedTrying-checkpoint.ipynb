{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "b7ee10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "7cfc3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def to_hls(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "def to_hsv(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def warp_perspective(img,mat):\n",
    "    return cv2.warpPerspective(img ,mat ,(1280,720))\n",
    "    \n",
    "def PerspectiveTransform(src,dst):\n",
    "    mat = cv2.getPerspectiveTransform(src,dst)\n",
    "    mat_inv = cv2.getPerspectiveTransform(dst,src)\n",
    "    return mat,mat_inv\n",
    "\n",
    "def isolate_color_mask(img, low_thresh, high_thresh):\n",
    "    return cv2.inRange(img, low_thresh, high_thresh)\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=4):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    return img\n",
    "\n",
    "\n",
    "def concat_frames(frames):\n",
    "    \n",
    "    scale_percent = 0.25\n",
    "    height = int(frames[0].shape[0] * 0.5)\n",
    "    width = int(frames[0].shape[1] * scale_percent)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(frames[0], dim, interpolation = cv2.INTER_AREA)\n",
    "    img2= cv2.resize(cv2.cvtColor(frames[4], cv2.COLOR_GRAY2BGR), dim, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "    for i in range(1,len(frames)):\n",
    "        try:\n",
    "            frames[i] = cv2.cvtColor(frames[i], cv2.COLOR_GRAY2BGR)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if(i==4):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            resized = cv2.resize(frames[i], dim, interpolation = cv2.INTER_AREA)\n",
    "            if i< (len(frames)/2):\n",
    "                img = cv2.hconcat([img,resized])\n",
    "            else:\n",
    "                img2 = cv2.hconcat([img2,resized])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    t = cv2.vconcat([img,img2])\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def get_right(image):\n",
    "    cropped_img=np.zeros_like(image)\n",
    "    cropped_img[:,image.shape[1]//2:image.shape[1]] = image[:,image.shape[1]//2:image.shape[1]]\n",
    "    return cropped_img\n",
    "\n",
    "def get_third_right(image):\n",
    "    cropped_img=np.zeros_like(image)\n",
    "    cropped_img[:,image.shape[1]*2//3:image.shape[1]] = image[:,image.shape[1]*2//3:image.shape[1]]\n",
    "    return cropped_img\n",
    "\n",
    "def get_left(image):\n",
    "    cropped_img=np.zeros_like(image)\n",
    "    cropped_img[:,0:image.shape[1]//2] = image[:,0:image.shape[1]//2]\n",
    "    return cropped_img\n",
    "\n",
    "def get_third_left(image):\n",
    "    cropped_img=np.zeros_like(image)\n",
    "    cropped_img[:,0:image.shape[1]//3] = image[:,0:image.shape[1]//3]\n",
    "    return cropped_img\n",
    "\n",
    "def calculateDistance(x1,y1,x2,y2):\n",
    "    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return dist\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "81ecfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSING THE POINTS TO USE IN THE PRESPECTIVE TRANSFORM\n",
    "input_top_left = [500,480]\n",
    "input_top_right = [780,480]\n",
    "input_bottom_right = [1200,700]\n",
    "input_bottom_left = [170,700]\n",
    "srcPts = np.float32([input_bottom_left,input_top_left,input_top_right,input_bottom_right])\n",
    "\n",
    "# STRETCH THE PREVIOUS POINTS ON THE WHOLE FRAME \n",
    "dstPts = np.float32([[0,720],[0,0],[1280,0],[1280,720]])\n",
    "\n",
    "# GET THE PATH \n",
    "path = sys.argv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "d4b93fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTIALIZING THE MEMORY (HISTORY OF LANES )\n",
    "\n",
    "# INITIALIZING THE POINTS FOR THE TWO LINES FORMING THE LANES\n",
    "old_j=0,0\n",
    "old_i=0,0\n",
    "old_jr=0,0\n",
    "old_ir=0,0\n",
    "\n",
    "#INITALIZNG THE CONTOURS\n",
    "old_centr=0,0\n",
    "old_contour=[]\n",
    "old_contour_w=[]\n",
    "\n",
    "# INTIALIZNG AN ARRAY TO HOLD THE VALUES OF THE LINE POINTS TO GET THE MEAN LATER ON \n",
    "arr=list()\n",
    "for i in range(4):\n",
    "    arr.append([])\n",
    "    \n",
    "# INITALIZE AN ARRAY TO HOLD THE POINTS OF THE EDGES OF THE CONOTUR\n",
    "old_pts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "30031d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrhe\\anaconda3\\envs\\MLenv\\lib\\site-packages\\ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "# CAPTUTRE THE VIDEO\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "# FRAME COUNTER\n",
    "counter = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret,img = cap.read()\n",
    "  if not ret:\n",
    "      break\n",
    "\n",
    "  # GET THE CENTRE OF THE IMAGE (THIS IS CONSIDERED THE CENTRE OF MY CAR)\n",
    "  me=(img.shape[1]//2,img.shape[0]//2)\n",
    "\n",
    "  # CREATE THE MATRICES TO DO THE TRANSFORM GIVEN THE SELECTED POINTS\n",
    "  mat,mat_inv = PerspectiveTransform(srcPts,dstPts)\n",
    "\n",
    "  # P IS A POINT AT THE CENTRE OF THE IMAGE REPRESENTING MY CAR BUT AT A HEIGHT THAT CAN BE SEEN\n",
    "  # IN THE PRESPECTIVE VIEW\n",
    "\n",
    "  p = me[0],600 # MY ORIGINAL POINT\n",
    "\n",
    "  # WE NEED TO GET THE LOCATION OF THE POINT AFTER TRANSFORMATION\n",
    "  px = (mat[0][0]*p[0] + mat[0][1]*p[1] + mat[0][2]) / ((mat[2][0]*p[0] + mat[2][1]*p[1] + mat[2][2]))\n",
    "  py = (mat[1][0]*p[0] + mat[1][1]*p[1] + mat[1][2]) / ((mat[2][0]*p[0] + mat[2][1]*p[1] + mat[2][2]))\n",
    "  me = (int(px), int(py)) # AFTER TRANSFORMATION\n",
    "\n",
    "  # GET THE BIRD_VIEW AND A COPY OF IT FOR VISUALIZATION\n",
    "  bird_view = warp_perspective(img,mat)\n",
    "  bird_cpy = bird_view.copy()\n",
    "\n",
    "  # ENLIGHTEN THE IMAGE QUITE A BIT FOR BETTER DETECTION !\n",
    "  lightened = adjust_gamma(bird_view,2)\n",
    "\n",
    "  # CREATE A YELLOW MASK AND A WHITE MASK THEN GET A MASK CONTAINING BOTH\n",
    "  white_mask = isolate_color_mask(to_hls(bird_view), np.array([0, 200, 0], dtype=np.uint8), np.array([200, 255, 255], dtype=np.uint8))\n",
    "  yellow_mask = isolate_color_mask(to_hls(lightened), np.array([10, 0, 100], dtype=np.uint8), np.array([40, 255, 255], dtype=np.uint8))\n",
    "  mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "  # APPLY CANNY ON THE MASK IMAGE TO GET THE dilated_edges\n",
    "  edges = cv2.Canny(mask,70,140)\n",
    "\n",
    "  # DILATE THE IMAGE TO CONNECT THE LINES AND MAKE IT EASIER TO GET THE CONTOUR\n",
    "  dilated_edges = cv2.dilate(edges,np.ones((7,7)))\n",
    "\n",
    "\n",
    "  ######\n",
    "  ## DEALING WITH THE LEFT LANE\n",
    "  #####\n",
    "\n",
    "\n",
    "  # GET THE CONTOURS FROM THE  LEFT SIDE OF THE IMAGE  (YELLOW LANE )\n",
    "  contours,_= cv2.findContours(get_third_left(dilated_edges), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "  # GET THE CONTOUR WITH THE MAXIMUM AREA\n",
    "  # IF THERE'S NO CONTOURS READ DUE TO NOISE OR THE BIGGEST CONTOUR\n",
    "  # IS QUITE SMALL THEN USE THE OLD CONTOUR\n",
    "  try:\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    if cv2.contourArea(c)>10000 :\n",
    "      old_contour=c\n",
    "    else :\n",
    "      raise Exception()\n",
    "  except:\n",
    "    c=old_contour\n",
    "\n",
    "\n",
    "  # GET THE EXTREME POINTS OF THE BIGGEST CONTOUR (THAT REPRESENTS A POLYGON SURROUNDING THE LANE)\n",
    "  left = tuple(c[c[:, :, 0].argmin()][0])\n",
    "  right = tuple(c[c[:, :, 0].argmax()][0])\n",
    "  top = tuple(c[c[:, :, 1].argmin()][0])\n",
    "  bottom = left[0] + right[0]-top[0] , left[1]\n",
    "  points = np.array([bottom,right,top,left])\n",
    "\n",
    "  # STORE THESE POINTS FOR FURTHER CALCULATIONS\n",
    "  for i,p in enumerate(points) :\n",
    "    arr[i].append(p)\n",
    "\n",
    "  # CALCULATE THE MEAN OF THE POINTS THAT VARIES QUITE A BIT\n",
    "  medx = np.mean([ar[0] for ar in arr[0]])\n",
    "  medy= np.mean([ar[1] for ar in arr[0]])\n",
    "  medk = np.mean([ar[1] for ar in arr[1]])\n",
    "\n",
    "\n",
    "  # AT THE START SAVE THESE POINTS AS HISTORY\n",
    "  if counter==0 :\n",
    "    old_pts = points\n",
    "\n",
    "\n",
    "\n",
    "  # AFTER SKIPPING SOME FRAMES TO ENSURE WE REACHED STABILITY\n",
    "  # USE THE CALCULATED MEAN TO ENSURE THAT THE MEASURED POINTS\n",
    "  # AREN'T FAR OFF THE MEANS\n",
    "\n",
    "   # IF THE POINT IS VALID THEN UPDATE THE HISTORY\n",
    "  if counter > 10 :\n",
    "\n",
    "    if right[1] > 1.2*medk :\n",
    "        points[1]= old_pts[1]\n",
    "        right= old_pts[1]\n",
    "    else:\n",
    "        old_pts[1]=right\n",
    "\n",
    "    if left[0] > 1.2*medx or left[1] > medy :\n",
    "      points[3]= old_pts[3]\n",
    "      left= old_pts[3]\n",
    "    else:\n",
    "      old_pts[3]=left\n",
    "\n",
    "\n",
    "    # GET TWO POINTS TO REPRESENT THE LEFT LANE\n",
    "  j =  (right[0]+top[0])//2,right[1]\n",
    "  i =  (bottom[0]+left[0])//2, bottom[1]\n",
    "\n",
    "\n",
    "    # IF THESE POINTS ARE FURTHER FROM THE POINTS OF THE PREVIOUS FRAME THEN DISCARD THEM !\n",
    "  if counter>20 :\n",
    "    if (calculateDistance(i[0],i[1],old_i[0],old_i[1]) > 200 and old_i!=(0,0)) or (calculateDistance(j[0],j[1],old_j[0],old_j[1]) > 200 and old_j!=(0,0)):\n",
    "      j = old_j\n",
    "      i = old_i\n",
    "    else:\n",
    "      old_i=i\n",
    "      old_j=j\n",
    "\n",
    "  # SOLVE THE EQUATION TO GET THE Y AND C\n",
    "  points = [i,j]\n",
    "  x_coords, y_coords = zip(*points)\n",
    "  A = vstack([x_coords,ones(len(x_coords))]).T\n",
    "  m, c_l = lstsq(A, y_coords)[0]\n",
    "\n",
    "  # GET TWO LINES LYING ON THE STRAIGHT LINE AND DRAW IT !\n",
    "  j_l = 1280, int(1280*m + c_l)\n",
    "  i_l = 0, int(0*m + c_l)\n",
    "\n",
    "  cv2.line(bird_cpy,i_l,j_l,(0,0,255),40)\n",
    "  \n",
    "  \n",
    "  # THE LOWEST POINT OF THE LEFT LANE \n",
    "  p=i\n",
    "\n",
    "  ######\n",
    "  ## DEALING WITH THE RIGHT LANE\n",
    "  #####\n",
    "\n",
    "  contours,_= cv2.findContours(get_third_right(dilated_edges), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "  # SINCE THAT THE RIGHT LANE IS CUT , SO WE NEED TO DRAW ALL THE CONTOURS , NOT JUST THE\n",
    "  # BIGGEST ONE. HERE WE USE BOUNDING RECTANGLE SINCE IT IS SMALL IN AREA\n",
    "  # SO IT CAN BE APPROXIMATED TO BE A RECTANGLE\n",
    "\n",
    "  for c in contours :\n",
    "    rect = cv2.boundingRect(c)\n",
    "    x,y,w,h = rect\n",
    "    cv2.rectangle(bird_cpy,(x,y),(x+w,y+h),(0,0,255),-1)\n",
    "\n",
    "  # IF THERE'S NO CONTOURS READ DUE TO NOISE THEN USE THE OLD CONTOUR\n",
    "  try:\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    old_contour_w=c\n",
    "  except:\n",
    "    c=old_contour_w\n",
    "\n",
    "\n",
    "\n",
    "  # GET THE POINT LYING ON THE BOUNDING RECTANGLE AND USE IT DRAW A STRAIGHT LINE THAT\n",
    "  # CAN BE APPROXIMATED TO BE THE LANE FOR DISTANCE CALCULATION\n",
    "\n",
    "  centr = x,y+h//2\n",
    "  if counter>30 :\n",
    "    if calculateDistance(centr[0],centr[1],old_centr[0],old_centr[1])>42 and old_centr!=(0,0) :\n",
    "      centr=old_centr\n",
    "    else:\n",
    "      old_centr=centr\n",
    "\n",
    "\n",
    "   # GET THE dilated_edges OF THE POLYGON THAT REPRESENTS THE AREA THAT\n",
    "   # THE CAR CAN MOVE IN AND COLOR IT BLUE \n",
    "  RL_U = (centr[0],0)\n",
    "  RL_D = (centr[0],720)\n",
    "  pts=np.array([RL_U,RL_D,i_l,j_l])\n",
    "  cv2.fillConvexPoly(bird_cpy, pts,color=(255, 0, 0))\n",
    "\n",
    "  # GET THE CENTRE OF THE LANE BY GETTING THE HALF POINT BETWEEN\n",
    "  # THE LOWEST POINT ON THE LEFT LANE AND THE RIGHT LANE \n",
    "  centreOfLane = ((p[0]+centr[0])//2,p[1])\n",
    "\n",
    "  # DIST IS THE DISTANCE BETWEEN THE CENTRE OF THE CAR AND THE CENTRE OF THE LANE IN PIXELS\n",
    "  dist = np.abs(centreOfLane[0]-me[0])\n",
    "  # DIST2 IS THE DISTANCE BETWEEN THE TWO LANES IN PIXELS \n",
    "  dist2=np.abs(p[0]-centr[0])\n",
    "  # SCALE IS THE DISTANCE IN PIXELS / DISTANCE IN METERS\n",
    "  scale = dist2/3\n",
    "\n",
    "  # PUT THE TEXT ON THE IMAGE \n",
    "  text = \"Distance : \"  + str(round(dist*(1/scale),3)) + \"m.\"\n",
    "  cv2.putText(img=bird_cpy, text=text, org=(400, 400), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=2, color=(0, 255, 0),thickness=5)\n",
    "\n",
    "\n",
    "# DRAW A POINT REPRESENTING THE CENTRE OF MY CAR\n",
    "  cv2.circle(bird_cpy,me,5,(255,255,0),10)\n",
    "\n",
    "\n",
    "# REGENERATE THE IMAGE TO THE NORMAL PRESPECTIVE \n",
    "  re_gen = warp_perspective(bird_cpy,mat_inv)\n",
    "\n",
    "# COPY THE ORIGINAL IMAGE FOR VISUALIZATION\n",
    "  imgg = img.copy()\n",
    "  \n",
    "# ADD THE REGENERATED IMAGE WITH THE ORIGINAL IMAGE \n",
    "  cv2.addWeighted(img, 0.5, re_gen, 0.5,0, imgg)\n",
    "  \n",
    "# PASS THE FULL PIPELINE TO CREATE A VIDEO CONTAINING THE STEPS \n",
    "  pipeline=[img,bird_view,yellow_mask,white_mask,edges,dilated_edges,bird_cpy,imgg]\n",
    "  full_pipeline=concat_frames(pipeline)\n",
    "\n",
    "  counter+=1\n",
    "\n",
    "  cv2.imshow(\"Full pipeline\",full_pipeline)\n",
    "\n",
    "  if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
